One promise of big data is the identification of correlations within that data that researchers would not have considered.  Big data is often described as “high in velocity, huge in volume, and diverse”; for example, Walmart is estimated to generate 2.5 petabytes of consumer data an hour.  Attempting to parse relationships from a constant flow of large, unstructured data such as this using purely human-based evaluation inevitably misses obscured patterns.  With the construction of advanced data algorithms, computers can perform correlational analysis for us.  Kitchen defines this as approach as “new data analytics” or gaining insights “born from the data”.  From these methods derived from big data, we can augment the scientific method to improve hypothesis formation and subsequent analysis.  For example, a well-designed algorithm may identify a correlation in single-cell RNA-sequencing results (which contain hundreds of thousands of data objects) that can lead to more focused experiments and analysis than those that would have been born of purely theory-based conjecture.  This new way of tackling problems envisions a profound future: solutions to problems could be identified more quickly and less resources would be spent.

Among these aspects of an efficient future is the rise of data science as an interdisciplinary field.  While every field focuses on certain aspects of their research, ultimately, they use many of the same processing and analysis methods.  As such, professionals from seemingly unrelated fields might be able to look at each other’s data and deduce meaning from them.  This is important as dynamic and complex systems held in big data are best approached by utilizing a diversity of thought.  This provides the opportunity to understand human development at a deeper level.  Imagine a team of researchers attempting to extract and interpret information about a nation (implying a big data set).  This team would produce a more holistic work if staffed by sociologists, geographers, ecologists, and anthropologists than one made entirely of a single discipline.  Difficulties created by knowledge difference across professions would, hypothetically, be mitigated by the universally shared skill of data science.  The seemingly insurmountable mountain of data could be parsed, interpreted by the respective experts, and amalgamated into a conclusion through this interdisciplinary collaboration.  Thus, researchers would model countries that come close to “n = all” or a “full-resolution” data set that considers every variable.

However, one must realize that the potential promises of big data are also fraught with problems.  Firstly, big data produced in a human development context are not widely used.  The data contain so much information that, in order to answer specific questions, researchers end up conducting more narrow studies that utilize smaller data.  In addition, data science is not a simple skill that can be mastered quickly.  Many researchers do not know how to properly use available statistical analysis methods and instead use them as black boxes: plug in the data and use whatever comes out the other end without rigorous evaluation.  Consequently, many published results may be entirely false, resources are wasted, and incorrect interpretations are made.
